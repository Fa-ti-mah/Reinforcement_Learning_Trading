{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bca49f-1dbf-4fc5-8eab-c442dfc005c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\feyis\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\feyis\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: gym in c:\\users\\feyis\\anaconda3\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: stable-baselines3 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: torch in c:\\users\\feyis\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\feyis\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from stable-baselines3) (0.29.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\feyis\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas gym stable-baselines3 torch matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "beda2d35-bf71-47ae-9206-f31375f167a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "class TradingEnv(gym.Env):  # Inherit from gymnasium.Env\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        \n",
    "        # Define the action and observation space\n",
    "        self.data = data\n",
    "        self.current_step = 0\n",
    "        self.balance = 10000  # Initial balance\n",
    "        self.shares_held = 0\n",
    "        self.net_worth = self.balance\n",
    "        \n",
    "        # Action space: hold, buy, sell\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "        \n",
    "        # Observation space: shape should match the features in your dataset\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=1, shape=(len(self.data.columns),), dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Ensure seed is set\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Initialize or reset variables\n",
    "        self.current_step = 0\n",
    "        self.balance = 10000\n",
    "        self.shares_held = 0\n",
    "        self.net_worth = self.balance\n",
    "        \n",
    "        # Return the initial observation and an empty info dictionary\n",
    "        return self._next_observation(), {}\n",
    "\n",
    "    def _next_observation(self):\n",
    "    # Get the observation (current step data)\n",
    "        obs = self.data.iloc[self.current_step].values\n",
    "\n",
    "    # Define the min and max values (you should ensure that your dataset has known min and max values)\n",
    "        obs_min = self.data.min().values\n",
    "        obs_max = self.data.max().values\n",
    "    \n",
    "    # Normalize the observation data using Min-Max scaling\n",
    "        normalized_obs = (obs - obs_min) / (obs_max - obs_min)\n",
    "\n",
    "    # Clip the normalized data to ensure all values fall within [0, 1]\n",
    "        normalized_obs = np.clip(normalized_obs, 0.0, 7.0)\n",
    "\n",
    "    # Cast the normalized observation to float32 to match the observation space\n",
    "        return normalized_obs.astype(np.float32)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        current_price = self.data.iloc[self.current_step]['Close']\n",
    "        self.current_step += 1\n",
    "\n",
    "        reward = 0\n",
    "        if action == 1:  # Buy\n",
    "            if self.balance > current_price:\n",
    "                self.shares_held += 25\n",
    "                self.balance -= current_price\n",
    "        elif action == 20:  # Sell\n",
    "            if self.shares_held > 0:\n",
    "                self.shares_held -= 25\n",
    "                self.balance += current_price\n",
    "                reward = current_price - self.data.iloc[self.current_step - 1]['Close']\n",
    "\n",
    "        self.net_worth = self.balance + self.shares_held * current_price\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "\n",
    "        # Return observation, reward, done, truncated (empty), and info\n",
    "        return self._next_observation(), reward, done, False, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f'Step: {self.current_step}, Net Worth: {self.net_worth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fffbe4e2-cbda-499b-8408-f8b990b511e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv('GME Data.csv')\n",
    "\n",
    "# Normalize the data\n",
    "data = (data - data.mean()) / data.std()\n",
    "\n",
    "Create the environment\n",
    "env = TradingEnv(data)\n",
    "\n",
    "\n",
    "check_env(env)\n",
    "\n",
    "Train the DQN agent\n",
    "model = DQN('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f4f3981-f79b-4fa7-832a-9556740aec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "for _ in range(len(data)):\n",
    "   action, _ = model.predict(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "      if done:\n",
    "         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06275cee-9700-4392-a136-95087d442d27",
   "metadata": {},
   "source": [
    "Evaluating the performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4371f-a266-46cf-a3fe-d16967354350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(env, model, num_episodes=1):\n",
    "    total_rewards = []\n",
    "    profits = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        starting_net_worth = env.net_worth\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        final_net_worth = env.net_worth\n",
    "        profit = final_net_worth - starting_net_worth\n",
    "        total_rewards.append(total_reward)\n",
    "        profits.append(profit)\n",
    "        \n",
    "        print(f\"Episode {episode + 1}: Total Reward: {total_reward}, Profit: {profit}\")\n",
    "\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    avg_profit = np.mean(profits)\n",
    "    \n",
    "    print(f\"\\nAverage Reward: {avg_reward}, Average Profit: {avg_profit}\")\n",
    "    return avg_reward, avg_profit\n",
    "\n",
    "# Evaluate the trained model\n",
    "evaluate_model(env, model, num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025280e-85b7-4d68-b866-dce9b38d108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_performance(env, model, num_episodes=1):\n",
    "    for episode in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        net_worths = [env.net_worth]\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            net_worths.append(env.net_worth)\n",
    "\n",
    "        # Plot net worth over time\n",
    "        plt.plot(net_worths, label=f\"Episode {episode + 1}\")\n",
    "    \n",
    "    plt.title('Net Worth Over Time')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Net Worth')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the model performance\n",
    "visualize_performance(env, model, num_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e0ffc-6756-477b-9ee4-f27c0b31fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_trades(env, model, num_episodes=1):\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        starting_net_worth = env.net_worth\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "\n",
    "        final_net_worth = env.net_worth\n",
    "        if final_net_worth > starting_net_worth:\n",
    "            wins += 1\n",
    "        else:\n",
    "            losses += 1\n",
    "\n",
    "    total_trades = wins + losses\n",
    "    win_rate = wins / total_trades if total_trades > 0 else 0\n",
    "    print(f\"Win Rate: {win_rate * 100:.2f}% ({wins} wins, {losses} losses)\")\n",
    "    \n",
    "# Evaluate win/loss ratio\n",
    "evaluate_trades(env, model, num_episodes=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
